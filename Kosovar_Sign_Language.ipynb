{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c346f19-880a-4474-ad34-efd48a3dd66f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip3 install tensorflow opencv-python mediapipe scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "170dd617-3ded-4389-85c4-f90672a06cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08860df7-5519-4ef6-beab-30e4797d04fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1470647d-c494-4039-9e85-46923606536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image,model):\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB) \n",
    "    image.flags.writeable = False   # Image is no longer writable\n",
    "    results = model.process(image) # Detecting or predicting \n",
    "    image.flags.writeable = True    # Image is writable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image,results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6e02850-74fc-4eaa-b32d-353dfb9661dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION) #Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) #Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) #Draw Left Hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) #Draw Right Hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "418ef1fd-7f8b-4dc4-b08d-2fccf4938e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                             mp_drawing.DrawingSpec(thickness=1, circle_radius=1),\n",
    "                             mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "                             ) #Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) #Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) #Draw Left Hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) #Draw Right Hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247483d6-b045-4389-997b-6d5b82459902",
   "metadata": {},
   "outputs": [],
   "source": [
    "#duke perdorur opencv marrim akses ne kamere\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        #read feed\n",
    "        ret, frame = cap.read() #fotoja ne webcam\n",
    "    \n",
    "        # Make detection \n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        print(results)\n",
    "\n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image,results)\n",
    "        \n",
    "        #show to user/screen\n",
    "        cv2.imshow(\"OpenCV Feed\", image)\n",
    "    \n",
    "        #breaking gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    # diskutabile duhet me provu ne rast se nuk mbyllet kamera mire - cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "422d64e2-d7a2-4291-8852-af88a96a3897",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Extracting keypoint values from the pose and hand landmarks \n",
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose,face,lh,rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7583a57c-3915-441d-a2b7-cfc25d7a6346",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3860930966.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[22], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    results.left_hand_landmarks.landmark. #secila landmark ka 3 variable x y dhe z, i kemi 21 landmarks te ndryshme nese e shumezojme\u001b[0m\n\u001b[0m                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "len(results.left_hand_landmarks.landmark)*3 #kalkulimi i 0 qe na duhen per secilen pjese fytyre, poze, duar\n",
    "#secila landmark ka 3 variable x y dhe z, i kemi 21 landmarks te ndryshme nese e shumezojme \n",
    "# me 3 (per x, y, z) athere na jep 63 dhe neve na duhet nje array me 63 vlera qe na duhet me kthy null nese nuk kemi landmark/hand ne frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f852f4dc-e304-4b56-b284-f89eb3725bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup folders for collection\n",
    "DATA_PATH = os.path.join(\"MP_Data\")\n",
    "\n",
    "#Veprimet qe mundohemi me i detektu\n",
    "actions = np.array(['A', 'B', 'C','Ç', 'D',])\n",
    "                   #  'Dh', 'E','Ë', 'F', 'G','Gj', 'H', 'I', 'J', 'K', 'L','Ll', 'M', \n",
    "                   #  'N','Nj', 'O', 'P', 'Q', 'R','Rr', 'S','Sh', 'T','Th', 'U', 'V', 'X','Xh', 'Y', 'Z','Zh',\n",
    "                   # 'Përshendetje','Mirë','Faleminderit', 'Më fal','Të dua','Nuk e di' ,'Asgjë', 'Kafe', 'Çaj','Ujë',\n",
    "                   #  'Çokollatë', 'Unë','Dua', 'Akullore', 'Kompjuteri', 'Telefon i menqur','Interneti', 'Vrapoj',\n",
    "                   #  'Eci'\n",
    "                   # ])\n",
    "\n",
    "no_sequences = 30\n",
    "sequence_length = 30\n",
    "start_folder = 30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76a1f62c-83d4-4761-b648-1c193b2dbdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ruajtja e seciles frame ne secilin folder te vetin\n",
    "for action in actions: \n",
    "    for sequence in range(no_sequences):\n",
    "        try: \n",
    "            os.makedirs(os.path.join(DATA_PATH,action, str(sequence)))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2647c1c-328d-4f46-9bb7-f9c9f967e5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Marrja e te dhenave \n",
    "#duke perdorur opencv marrim akses ne kamere\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    #loop through actions\n",
    "    #per secilin veprim i marrim nga 30 frames/videos\n",
    "    for action in actions:\n",
    "        for sequence in range(no_sequences):\n",
    "            for frame_num in range(sequence_length):\n",
    "                \n",
    "                #read feed\n",
    "                ret, frame = cap.read() #fotoja ne webcam\n",
    "\n",
    "                # Make detection \n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "                print(results)\n",
    "        \n",
    "                # Draw landmarks\n",
    "                draw_styled_landmarks(image,results)\n",
    "\n",
    "                #Apply wait logic\n",
    "                if frame_num == 0:\n",
    "                    cv2.putText(image, 'Starting collection',\n",
    "                                (120,200),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),1,cv2.LINE_AA)\n",
    "                    cv2.putText(image, 'Collecting frames for {} Video number {}'.format(action,sequence),\n",
    "                                (15,12),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,255),1,cv2.LINE_AA)\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                    cv2.waitKey(2000)\n",
    "                else:\n",
    "                    cv2.putText(image, 'Collecting frames for {} Video number {}'.format(action,sequence),\n",
    "                                (15,12),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,255),1,cv2.LINE_AA)\n",
    "\n",
    "                #extract keypoints \n",
    "                keypoints = extract_keypoints(results)\n",
    "                npy_path = os.path.join(DATA_PATH,action,str(sequence),str(frame_num))\n",
    "                np.save(npy_path, keypoints)\n",
    "                \n",
    "               \n",
    "                #breaking gracefully\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    # diskutabile duhet me provu ne rast se nuk mbyllet kamera mire - cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f7690b8-c805-407f-900c-5b982cf0c0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f37f7e55-2593-4833-a658-27bbf120cbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1ec6ce2-655b-4480-8696-29c3f9f3517c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sequences, labels = [],[]\n",
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        window = [] #frames qe i kemi per ate sekuence 30 videos/sekuenca\n",
    "        for frame_num in range(sequence_length):  \n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res) #kryhet video 1 dhe i shtohet sekuencave ne rreshtin tjeter \n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b388b9f4-5f74-4b37-8a64-efc5a9236232",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3cd4ab8-21a3-438e-9ddd-51d4c81f7460",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b183435-a245-4c99-a671-b55e67c4aed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85cd2e86-0641-4c16-b28c-29c96efa4967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482f8a60-9552-4d00-b3db-c8e89106c0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir) #observimi i modelit derisa trajnohet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eff888b2-f099-4a5c-8349-781c0af51611",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64,return_sequences=True,activation='relu',input_shape=(30,1662))) #X.shape (90,30,1662) e marrim 30 dhe 1662 na duhet me shiku\n",
    "model.add(LSTM(128,return_sequences=True,activation='relu'))\n",
    "model.add(LSTM(64,return_sequences=False,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(actions.shape[0],activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9580fa56-2c2a-4c3e-b72d-6300fe68f401",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1081b05-9646-41db-9a44-51fddeebf816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mundemi me ndal edhe ma heret kur te shohim qe po performon mire modeli  \n",
    "model.fit(X_train,y_train,epochs=140,callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f705202-ddb3-4b0a-8789-0203b6b22d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parashikimet\n",
    "res = model.predict(X_test)\n",
    "actions[np.argmax(res[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d7c144c-09c0-460f-b1e8-24d3bb52a014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(y_test[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1b27472-5c01-4e7c-9071-08ca83ebc2b0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#ruajtja e modelit/weights\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maction.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#ruajtja e modelit/weights\n",
    "model.save('action.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75f66a5b-84a1-4d99-9004-a681c7fa47e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nese e fshijme modelin shkojme e bejme rebuild tek ky cell model = Sequential() ...\n",
    "#Pastaj e bejme compile dhe vazhdojm me load\n",
    "model.load_weights('action.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cebbbe36-78d5-4952-83cb-6fbdb24d4650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.models.save_model(model, 'action.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "853091bb-def3-4098-a11f-fb56b416932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vleresimi se sa mire po performon modeli yne \n",
    "from sklearn.metrics import multilabel_confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db9bf2f-200f-498d-b548-e2b688655acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)\n",
    "ytrue = np.argmax(y_test,axis=1).tolist()\n",
    "yhat = np.argmax(yhat,axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d322ac6a-fea3-4ef0-be36-d38519465ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_confusion_matrix(ytrue,yhat)\n",
    "accuracy_score(ytrue,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9677c3b-7c35-4a07-84eb-9317340851ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(245,117,16),(117,245,16),(16,117,245)]\n",
    "#shfaq te gjitha fjalet dhe prob. e tyre \n",
    "def prob_viz(res,actions,input_frame,colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num,prob in enumerate(res):\n",
    "        cv2.rectangle(output_frame, (0,60+num*40),(int(prob*100),90+num*40),colors[num],-1)\n",
    "        cv2.putText(output_frame,actions[num],(0,85+num*40),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2,cv2.LINE_AA)\n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32a2b58-451b-4197-8588-e9bfa76ba3d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Testing in real time\n",
    "#duke perdorur opencv marrim akses ne kamere\n",
    "sequence = [] #marrja e frames qe pastaj me i bo pass dhe me parashiku\n",
    "sentence = []\n",
    "predictions = []\n",
    "threshold = 0.4 #confidence matrix, i marrim rez vetem nese jane mbi nje vlere te caktuar\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        #read feed\n",
    "        ret, frame = cap.read() #fotoja ne webcam\n",
    "    \n",
    "        # Make detection \n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        print(results)\n",
    "\n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image,results)\n",
    "        #Prediction logic \n",
    "        keypoints = extract_keypoints(results)\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:]\n",
    "        \n",
    "        if len(sequence) == 30:\n",
    "            res = model.predict(np.expand_dims(sequence,axis=0))[0]\n",
    "            print(actions[np.argmax(res)])\n",
    "            predictions.append(np.argmax(res))\n",
    "    \n",
    "\n",
    "            #Logjika vizualizimit\n",
    "            if np.unique(predictions[-10:])[0] == np.argmax(res):            \n",
    "                if res[np.argmax(res)] > threshold:\n",
    "                    if len(sentence) > 0:\n",
    "                        if actions[np.argmax(res)] != sentence[-1]:\n",
    "                            sentence.append(actions[np.argmax(res)])\n",
    "                    else:\n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "    \n",
    "            if len(sentence) > 5:\n",
    "                sentence = sentence[-5:]\n",
    "    \n",
    "            image = prob_viz(res,actions,image,colors)\n",
    "\n",
    "        cv2.rectangle(image, (0,0), (640,40), (245,117,16),-1)\n",
    "        cv2.putText(image,' '.join(sentence),(3,30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2,cv2.LINE_AA)\n",
    "        \n",
    "        #show to user/screen\n",
    "        cv2.imshow(\"OpenCV Feed\", image)\n",
    "    \n",
    "        #breaking gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    # diskutabile duhet me provu ne rast se nuk mbyllet kamera mire - cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d680fc2-fdb7-45e4-b21a-1ec8bca68d54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
